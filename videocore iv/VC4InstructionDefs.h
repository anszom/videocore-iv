//
//  VC4InstructionDefs.h
//  videocore iv
//
//  Created by Pascal Werz on 05/02/2016.
//  Copyright Â© 2016 Pascal Werz. All rights reserved.
//


// my own extensions to DisasmOperand.type
// use the rightmost bits of the field to (try to) avoid collisions with Hooper future new types
#define DISASM_OPERAND_PREDECREMENT                     0x0001000000000000llu
#define DISASM_OPERAND_POSTINCREMENT                    0x0002000000000000llu



#define OP_REGISTER(r)      (DISASM_OPERAND_REGISTER_TYPE | DISASM_BUILD_REGISTER_CLS_MASK(RegClass_GeneralPurposeRegister) | DISASM_BUILD_REGISTER_INDEX_MASK(r))


typedef enum
{
    VC4_COND_EQ =  0,
    VC4_COND_NE =  1,
    VC4_COND_LO =  2, VC4_COND_ULT = VC4_COND_LO,
    VC4_COND_HS =  3, VC4_COND_UGE = VC4_COND_HS,
    VC4_COND_MI =  4,
    VC4_COND_PL =  5,
    VC4_COND_VS =  6,
    VC4_COND_VC =  7,
    VC4_COND_HI =  8, VC4_COND_UGT = VC4_COND_HI,
    VC4_COND_LS =  9, VC4_COND_ULE = VC4_COND_LS,
    VC4_COND_GE = 10, VC4_COND_SGE = VC4_COND_GE,
    VC4_COND_LT = 11, VC4_COND_SLT = VC4_COND_LT,
    VC4_COND_GT = 12, VC4_COND_SGT = VC4_COND_GT,
    VC4_COND_LE = 13, VC4_COND_SLE = VC4_COND_LE, VC4_MAX_CONDITIONAL = VC4_COND_LE,
    VC4_COND_T  = 14,
    VC4_COND_F  = 15,
    VC4_COND_COUNT,
    VC4_COND_UNKNOWN = 16
} VC4ConditionCode;



enum
{
    VC4_INST_OTHER = 0,

    VC4_INST_MOV,
    VC4_INST_CMN        = VC4_INST_MOV + 1,
    VC4_INST_ADD        = VC4_INST_MOV + 2,
    VC4_INST_BIC        = VC4_INST_MOV + 3,
    VC4_INST_MUL        = VC4_INST_MOV + 4,
    VC4_INST_EOR        = VC4_INST_MOV + 5,
    VC4_INST_SUB        = VC4_INST_MOV + 6,
    VC4_INST_AND        = VC4_INST_MOV + 7,
    VC4_INST_NOT        = VC4_INST_MOV + 8,
    VC4_INST_ROR        = VC4_INST_MOV + 9,
    VC4_INST_CMP        = VC4_INST_MOV + 10,
    VC4_INST_RSUB       = VC4_INST_MOV + 11,
    VC4_INST_BTEST      = VC4_INST_MOV + 12,
    VC4_INST_OR         = VC4_INST_MOV + 13,
    VC4_INST_BMASK      = VC4_INST_MOV + 14,
    VC4_INST_MAX        = VC4_INST_MOV + 15,
    VC4_INST_BSET       = VC4_INST_MOV + 16,
    VC4_INST_MIN        = VC4_INST_MOV + 17,
    VC4_INST_BCLR       = VC4_INST_MOV + 18,
    VC4_INST_ADDSCALE2  = VC4_INST_MOV + 19,
    VC4_INST_BCHG       = VC4_INST_MOV + 20,
    VC4_INST_ADDSCALE4  = VC4_INST_MOV + 21,
    VC4_INST_ADDSCALE8  = VC4_INST_MOV + 22,
    VC4_INST_ADDSCALE16 = VC4_INST_MOV + 23,
    VC4_INST_SIGNEXT    = VC4_INST_MOV + 24,
    VC4_INST_NEG        = VC4_INST_MOV + 25,
    VC4_INST_LSR        = VC4_INST_MOV + 26,
    VC4_INST_MSB        = VC4_INST_MOV + 27,
    VC4_INST_SHL        = VC4_INST_MOV + 28,
    VC4_INST_BITREV     = VC4_INST_MOV + 29,
    VC4_INST_ASR        = VC4_INST_MOV + 30,
    VC4_INST_ABS        = VC4_INST_MOV + 31,

    VC4_INST_BKPT,
    VC4_INST_NOP,
    VC4_INST_SLEEP,
    VC4_INST_USER,
    VC4_INST_EI,
    VC4_INST_DI,
    VC4_INST_CBCLR,
    VC4_INST_CBADD1,
    VC4_INST_CBADD2,
    VC4_INST_CBADD3,
    VC4_INST_RTI,
    VC4_INST_B,
    VC4_INST_BCMP,
    VC4_INST_BL,
    VC4_INST_TBB,
    VC4_INST_TBS,
    VC4_INST_LDCPUID,
    VC4_INST_SWI,
    VC4_INST_POP,
    VC4_INST_POPMULTIPLE,
    VC4_INST_POPPC,
    VC4_INST_PUSH,
    VC4_INST_PUSHMULTIPLE,
    VC4_INST_PUSHLR,
    VC4_INST_LDU32,
    VC4_INST_LDU16 = VC4_INST_LDU32 + 1,
    VC4_INST_LDU8  = VC4_INST_LDU32 + 2,
    VC4_INST_LDS16 = VC4_INST_LDU32 + 3,
    VC4_INST_LDSPOFFSET,
    VC4_INST_LDREGOFFSET,
    VC4_INST_STU32,
    VC4_INST_STU16 = VC4_INST_STU32 + 1,
    VC4_INST_STU8  = VC4_INST_STU32 + 2,
    VC4_INST_STS16 = VC4_INST_STU32 + 3,
    VC4_INST_STSPOFFSET,
    VC4_INST_STREGOFFSET,
    VC4_INST_LEA,
    VC4_INST_ADDCMPB,
    VC4_INST_ADDICMPB,
    VC4_INST_MULHD,
    VC4_INST_DIV,
    VC4_INST_ADDS,
    VC4_INST_SUBS,
    VC4_INST_SHLS,
    VC4_INST_CLIPSH,
    VC4_INST_ADDSCALE32,
    VC4_INST_ADDSCALE64,
    VC4_INST_ADDSCALE128,
    VC4_INST_ADDSCALE256,
    VC4_INST_COUNT,
    VC4_INST_SUBSCALE2,
    VC4_INST_SUBSCALE4,
    VC4_INST_SUBSCALE8,
    VC4_INST_SUBSCALE16,
    VC4_INST_SUBSCALE32,
    VC4_INST_SUBSCALE64,
    VC4_INST_SUBSCALE128,
    VC4_INST_SUBSCALE256,
    VC4_INST_MOVPCR,


    VC4_INST_FADD,
    VC4_INST_FSUB   = VC4_INST_FADD + 1,
    VC4_INST_FMUL   = VC4_INST_FADD + 2,
    VC4_INST_FDIV   = VC4_INST_FADD + 3,
    VC4_INST_FCMP   = VC4_INST_FADD + 4,
    VC4_INST_FABS   = VC4_INST_FADD + 5,
    VC4_INST_FRSB   = VC4_INST_FADD + 6,
    VC4_INST_FMAX   = VC4_INST_FADD + 7,
    VC4_INST_FRCP   = VC4_INST_FADD + 8,
    VC4_INST_FRSQRT = VC4_INST_FADD + 9,
    VC4_INST_FNMUL  = VC4_INST_FADD + 10,
    VC4_INST_FMIN   = VC4_INST_FADD + 11,
    VC4_INST_FCEIL  = VC4_INST_FADD + 12,
    VC4_INST_FFLOOR = VC4_INST_FADD + 13,
    VC4_INST_FLOG2  = VC4_INST_FADD + 14,
    VC4_INST_FEXP2  = VC4_INST_FADD + 15,
    VC4_INST_FTRUNC,
    VC4_INST_FLOOR  = VC4_INST_FTRUNC + 1,
    VC4_INST_FLTS   = VC4_INST_FTRUNC + 2,
    VC4_INST_FLTU   = VC4_INST_FTRUNC + 3,

    VC4_INST_VECTOR,
};
